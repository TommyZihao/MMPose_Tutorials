{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63f1dd0a-8685-40fd-b5d7-3218f97ac899",
   "metadata": {},
   "source": [
    "# 2D Human Pose预训练模型预测\n",
    "\n",
    "参考文档：https://github.com/open-mmlab/mmpose/blob/master/demo/docs/2d_human_pose_demo.md\n",
    "\n",
    "作者：同济子豪兄 2022-06-06\n",
    "\n",
    "如果报错`CUDA out of memory.`则重启前面几个代码的`kernel`即可。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff424e2-8d49-4f7c-8e81-24a957d1b7b9",
   "metadata": {},
   "source": [
    "## 进入 MMPose 主目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c24d56aa-5528-4561-bb1c-33bcffe2c852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.git',\n",
       " '.circleci',\n",
       " '.dev_scripts',\n",
       " '.github',\n",
       " '.gitignore',\n",
       " '.pre-commit-config.yaml',\n",
       " '.pylintrc',\n",
       " '.readthedocs.yml',\n",
       " 'CITATION.cff',\n",
       " 'LICENSE',\n",
       " 'MANIFEST.in',\n",
       " 'README.md',\n",
       " 'README_CN.md',\n",
       " 'configs',\n",
       " 'demo',\n",
       " 'docker',\n",
       " 'docs',\n",
       " 'mmpose',\n",
       " 'model-index.yml',\n",
       " 'pytest.ini',\n",
       " 'requirements.txt',\n",
       " 'requirements',\n",
       " 'resources',\n",
       " 'setup.cfg',\n",
       " 'setup.py',\n",
       " 'tests',\n",
       " 'tools',\n",
       " 'mmpose.egg-info',\n",
       " 'checkpoints',\n",
       " 'data',\n",
       " 'outputs']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('mmpose')\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c272e015-6112-495d-b407-531fcf46b9bd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 自顶向下`top_down`算法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d4b2a2-cdf0-40c9-99d6-e5c0bdfae73a",
   "metadata": {},
   "source": [
    "### 用目标检测预测框作为`top_down`算法的输入框输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cddc453-bb4d-49e8-8b70-b3be1154712c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from http path: https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth\n",
      "load checkpoint from http path: https://download.openmmlab.com/mmpose/top_down/hrnet/hrnet_w48_coco_256x192-b9e0b3ab_20200708.pth\n"
     ]
    }
   ],
   "source": [
    "!python demo/top_down_img_demo_with_mmdet.py \\\n",
    "        demo/mmdetection_cfg/faster_rcnn_r50_fpn_coco.py \\\n",
    "        https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth \\\n",
    "        configs/body/2d_kpt_sview_rgb_img/topdown_heatmap/coco/hrnet_w48_coco_256x192.py \\\n",
    "        https://download.openmmlab.com/mmpose/top_down/hrnet/hrnet_w48_coco_256x192-b9e0b3ab_20200708.pth \\\n",
    "        --img data/TongjiDancer.png \\\n",
    "        --out-img-root outputs/B1/B1_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee67f933-2a6f-4146-88b5-c53d1399e866",
   "metadata": {},
   "source": [
    "### 用标注框作为`top_down`算法的输入框输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd1ae34f-1fc2-4374-8ad8-c62169c2a4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "load checkpoint from http path: https://download.openmmlab.com/mmpose/top_down/hrnet/hrnet_w48_coco_256x192-b9e0b3ab_20200708.pth\n"
     ]
    }
   ],
   "source": [
    "!python demo/top_down_img_demo.py \\\n",
    "        configs/body/2d_kpt_sview_rgb_img/topdown_heatmap/coco/hrnet_w48_coco_256x192.py \\\n",
    "        https://download.openmmlab.com/mmpose/top_down/hrnet/hrnet_w48_coco_256x192-b9e0b3ab_20200708.pth \\\n",
    "        --img-root tests/data/coco/ \\\n",
    "        --json-file tests/data/coco/test_coco.json \\\n",
    "        --out-img-root outputs/B1/B1_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7600f5-c4be-47f5-95b4-147213edabed",
   "metadata": {},
   "source": [
    "### 单帧输入模型的视频预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9928a78-d7f2-42b1-a3fa-e64035e4a4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model...\n",
      "load checkpoint from http path: https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth\n",
      "load checkpoint from http path: https://download.openmmlab.com/mmpose/top_down/hrnet/hrnet_w48_coco_256x192-b9e0b3ab_20200708.pth\n",
      "Running inference...\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>   ] 95/102, 2.3 task/s, elapsed: 41s, ETA:     3s\n"
     ]
    }
   ],
   "source": [
    "!python demo/top_down_video_demo_with_mmdet.py \\\n",
    "        demo/mmdetection_cfg/faster_rcnn_r50_fpn_coco.py \\\n",
    "        https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth \\\n",
    "        configs/body/2d_kpt_sview_rgb_img/topdown_heatmap/coco/hrnet_w48_coco_256x192.py \\\n",
    "        https://download.openmmlab.com/mmpose/top_down/hrnet/hrnet_w48_coco_256x192-b9e0b3ab_20200708.pth \\\n",
    "        --video-path data/TongjiDancerClub.MOV \\\n",
    "        --out-video-root outputs/B1/B1_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd383ab-0135-4a44-9c3d-659f32b02954",
   "metadata": {},
   "source": [
    "### 多帧输入模型的视频预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c42b28-a6fa-4495-8142-02e0251691e3",
   "metadata": {},
   "source": [
    "使用`--use-multi-frames`参数，将视频前后多帧画面输入模型用于姿态预测。\n",
    "\n",
    "使用`--online`参数，仅输入该帧之前的帧，不输入该帧之后的帧。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01931340-af91-4d33-922c-1cad7888865c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model...\n",
      "load checkpoint from http path: https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth\n",
      "load checkpoint from http path: https://download.openmmlab.com/mmpose/top_down/posewarper/hrnet_w48_posetrack18_384x288_posewarper_stage2-4abf88db_20211130.pth\n",
      "Running inference...\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 66/66, 0.5 task/s, elapsed: 126s, ETA:     0s\n"
     ]
    }
   ],
   "source": [
    "!python demo/top_down_video_demo_with_mmdet.py \\\n",
    "        demo/mmdetection_cfg/faster_rcnn_r50_fpn_coco.py \\\n",
    "        https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth \\\n",
    "        configs/body/2d_kpt_sview_rgb_vid/posewarper/posetrack18/hrnet_w48_posetrack18_384x288_posewarper_stage2.py \\\n",
    "        https://download.openmmlab.com/mmpose/top_down/posewarper/hrnet_w48_posetrack18_384x288_posewarper_stage2-4abf88db_20211130.pth  \\\n",
    "        --video-path https://user-images.githubusercontent.com/87690686/137440639-fb08603d-9a35-474e-b65f-46b5c06b68d6.mp4 \\\n",
    "        --out-video-root outputs/B1/B1_4 \\\n",
    "        --use-multi-frames --online"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3d85ba-ad01-4c1b-8e15-07642829e028",
   "metadata": {},
   "source": [
    "### 全图输入模型的视频预测\n",
    "\n",
    "We also provide a video demo which does not require human bounding box detection. If the video is cropped with the human centered in the screen, we can simply use the full image as the model input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b698955a-ef57-41be-aa6d-3effacb90f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model...\n",
      "load checkpoint from http path: https://download.openmmlab.com/mmpose/top_down/vipnas/vipnas_res50_coco_256x192-cc43b466_20210624.pth\n",
      "Downloading: \"https://download.openmmlab.com/mmpose/top_down/vipnas/vipnas_res50_coco_256x192-cc43b466_20210624.pth\" to /home/featurize/.cache/torch/hub/checkpoints/vipnas_res50_coco_256x192-cc43b466_20210624.pth\n",
      "100%|███████████████████████████████████████| 28.0M/28.0M [00:00<00:00, 104MB/s]\n",
      "\u001b[0;39m[tls @ 0x55e3aacf3a80] \u001b[0m\u001b[1;31merror:00000000:lib(0):func(0):reason(0)\n",
      "\u001b[0m\u001b[0;35m[mov,mp4,m4a,3gp,3g2,mj2 @ 0x55e3adbfb5c0] \u001b[0m\u001b[1;31mstream 0, offset 0x30: partial file\n",
      "\u001b[0mRunning inference...\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>] 2966/2966, 15.7 task/s, elapsed: 189s, ETA:     0s\n"
     ]
    }
   ],
   "source": [
    "!python demo/top_down_video_demo_full_frame_without_det.py \\\n",
    "        configs/body/2d_kpt_sview_rgb_img/topdown_heatmap/coco/vipnas_res50_coco_256x192.py \\\n",
    "         https://download.openmmlab.com/mmpose/top_down/vipnas/vipnas_res50_coco_256x192-cc43b466_20210624.pth \\\n",
    "        --video-path https://user-images.githubusercontent.com/87690686/169808764-29e5678c-6762-4f43-8666-c3e60f94338f.mp4 \\\n",
    "        --out-video-root outputs/B1/B1_5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd36abfc-31f5-4e52-866d-87e9e670e718",
   "metadata": {},
   "source": [
    "## 自底向上`Bottom-Up`算法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5078404b-c30d-49f8-bb97-a32045026523",
   "metadata": {},
   "source": [
    "### 单张图像预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d434a232-411c-44f3-ae64-f7117b8dcade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from http path: https://download.openmmlab.com/mmpose/bottom_up/hrnet_w32_coco_512x512-bcb8c247_20200816.pth\n",
      "Downloading: \"https://download.openmmlab.com/mmpose/bottom_up/hrnet_w32_coco_512x512-bcb8c247_20200816.pth\" to /home/featurize/.cache/torch/hub/checkpoints/hrnet_w32_coco_512x512-bcb8c247_20200816.pth\n",
      "100%|█████████████████████████████████████████| 109M/109M [00:01<00:00, 109MB/s]\n",
      "[                                                  ] 0/4, elapsed: 0s, ETA:/home/featurize/work/MMPose教程/mmpose/mmpose/core/post_processing/group.py:240: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  y = ind // W\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 4/4, 0.5 task/s, elapsed: 8s, ETA:     0s\n"
     ]
    }
   ],
   "source": [
    "!python demo/bottom_up_img_demo.py \\\n",
    "        configs/body/2d_kpt_sview_rgb_img/associative_embedding/coco/hrnet_w32_coco_512x512.py \\\n",
    "        https://download.openmmlab.com/mmpose/bottom_up/hrnet_w32_coco_512x512-bcb8c247_20200816.pth \\\n",
    "        --img-path tests/data/coco/ \\\n",
    "        --out-img-root outputs/B1/B1_6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbca5c2-d7b3-4e93-b1f1-5b3fadcb0c2c",
   "metadata": {},
   "source": [
    "### 视频预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5eba779-3a45-4c11-baea-ced185ab07ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from http path: https://download.openmmlab.com/mmpose/bottom_up/hrnet_w32_coco_512x512-bcb8c247_20200816.pth\n",
      "/home/featurize/work/MMPose教程/mmpose/mmpose/core/post_processing/group.py:240: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  y = ind // W\n"
     ]
    }
   ],
   "source": [
    "!python demo/bottom_up_video_demo.py \\\n",
    "        configs/body/2d_kpt_sview_rgb_img/associative_embedding/coco/hrnet_w32_coco_512x512.py \\\n",
    "        https://download.openmmlab.com/mmpose/bottom_up/hrnet_w32_coco_512x512-bcb8c247_20200816.pth \\\n",
    "        --video-path demo/resources/demo.mp4 \\\n",
    "        --out-video-root outputs/B1/B1_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33493269-6fdf-4fba-aa64-513848c86b8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
