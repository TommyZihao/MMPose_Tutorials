{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63f1dd0a-8685-40fd-b5d7-3218f97ac899",
   "metadata": {},
   "source": [
    "# 2D人体姿态追踪 预训练模型预测\n",
    "\n",
    "参考文档：https://github.com/open-mmlab/mmpose/blob/master/demo/docs/2d_pose_tracking_demo.md\n",
    "\n",
    "作者：同济子豪兄 2022-06-06\n",
    "\n",
    "如果报错`CUDA out of memory.`则重启前面几个代码的`kernel`即可。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff424e2-8d49-4f7c-8e81-24a957d1b7b9",
   "metadata": {},
   "source": [
    "## 进入 MMPose 主目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c24d56aa-5528-4561-bb1c-33bcffe2c852",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('mmpose')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba65cbfc-6255-4668-b344-9985e77e7464",
   "metadata": {},
   "source": [
    "## 2D Top-Down Video Human Pose Tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec858a0-95a8-46b7-944d-c3caba82b8a6",
   "metadata": {},
   "source": [
    "mmpose原生追踪算法原理：https://github.com/open-mmlab/mmpose/blob/master/mmpose/apis/inference_tracking.py#L39-L116\n",
    "\n",
    "（根据iou或者oks算一个贪心的匹配，极其简易的追踪算法）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0789df-4d1d-48e3-8afd-b7600ece0fdc",
   "metadata": {},
   "source": [
    "### 单帧视频预测\n",
    "\n",
    "--bbox-thr 目标检测框阈值，默认为0.3\n",
    "\n",
    "--kpt-thr 关键点检测阈值，默认为0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27f40fee-da99-443b-a29f-dcfc1386d759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model...\n",
      "load checkpoint from http path: https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth\n",
      "load checkpoint from http path: https://download.openmmlab.com/mmpose/top_down/resnet/res50_coco_256x192-ec54d7f3_20200709.pth\n",
      "Running inference...\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 99/99, 4.1 task/s, elapsed: 24s, ETA:     0s\n"
     ]
    }
   ],
   "source": [
    "!python demo/top_down_pose_tracking_demo_with_mmdet.py \\\n",
    "        demo/mmdetection_cfg/faster_rcnn_r50_fpn_coco.py \\\n",
    "        https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth \\\n",
    "        configs/body/2d_kpt_sview_rgb_img/topdown_heatmap/coco/res50_coco_256x192.py \\\n",
    "        https://download.openmmlab.com/mmpose/top_down/resnet/res50_coco_256x192-ec54d7f3_20200709.pth \\\n",
    "        --video-path data/mot_people_short.mp4 \\\n",
    "        --out-video-root outputs/D1/D1_1_top_down_tracking_single_frame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae1d269-757c-49ee-be43-2e3b250aecc1",
   "metadata": {},
   "source": [
    "### 多帧视频预测（速度会慢一些）\n",
    "\n",
    "使用`--use-multi-frames`参数，将视频前后多帧画面输入模型用于姿态预测。\n",
    "\n",
    "使用`--online`参数，仅输入该帧之前的帧，不输入该帧之后的帧。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cac29e0c-b16f-49d3-b0af-8503b075deba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model...\n",
      "load checkpoint from http path: https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth\n",
      "load checkpoint from http path: https://download.openmmlab.com/mmpose/top_down/posewarper/hrnet_w48_posetrack18_384x288_posewarper_stage2-4abf88db_20211130.pth\n",
      "Running inference...\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 99/99, 0.5 task/s, elapsed: 181s, ETA:     0s\n"
     ]
    }
   ],
   "source": [
    "!python demo/top_down_pose_tracking_demo_with_mmdet.py \\\n",
    "        demo/mmdetection_cfg/faster_rcnn_r50_fpn_coco.py \\\n",
    "        https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth \\\n",
    "        configs/body/2d_kpt_sview_rgb_vid/posewarper/posetrack18/hrnet_w48_posetrack18_384x288_posewarper_stage2.py \\\n",
    "        https://download.openmmlab.com/mmpose/top_down/posewarper/hrnet_w48_posetrack18_384x288_posewarper_stage2-4abf88db_20211130.pth  \\\n",
    "        --video-path data/mot_people_short.mp4 \\\n",
    "        --out-video-root outputs/D1/D1_2_top_down_tracking_multi_frames \\\n",
    "        --use-multi-frames \\\n",
    "        --online"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bf5008-8574-4239-bb3e-104a4a37b13b",
   "metadata": {},
   "source": [
    "## 2D Bottom-Up Video Human Pose Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83a33877-a956-4c47-8caa-cf49d52eb13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from http path: https://download.openmmlab.com/mmpose/bottom_up/hrnet_w32_coco_512x512-bcb8c247_20200816.pth\n",
      "/home/featurize/work/MMPose教程/mmpose/mmpose/core/post_processing/group.py:240: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  y = ind // W\n"
     ]
    }
   ],
   "source": [
    "!python demo/bottom_up_pose_tracking_demo.py \\\n",
    "        configs/body/2d_kpt_sview_rgb_img/associative_embedding/coco/hrnet_w32_coco_512x512.py \\\n",
    "        https://download.openmmlab.com/mmpose/bottom_up/hrnet_w32_coco_512x512-bcb8c247_20200816.pth \\\n",
    "        --video-path data/mot_people_short.mp4 \\\n",
    "        --out-video-root outputs/D1/D1_5_bottom_up_tracking_video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b934ae-e3bf-479b-940c-9710df7c86e7",
   "metadata": {},
   "source": [
    "## 基于 MMTracking 的 2D Top-Down Video Human Pose Tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4086f085-dcba-49f6-832a-944b1fc2eed5",
   "metadata": {},
   "source": [
    "### 安装MMTracking\n",
    "\n",
    "MMTracking教程：https://www.bilibili.com/video/BV1s44y1g75J"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2004e9ba-7811-479e-8d48-c4fe871c66b9",
   "metadata": {},
   "source": [
    "### 单帧视频预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1587b92d-6ee2-4ad5-9ef2-f4159d20f606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model...\n",
      "/home/featurize/work/MMPose教程/mmtracking/mmtrack/models/mot/tracktor.py:28: UserWarning: DeprecationWarning: pretrains is deprecated, please use \"init_cfg\" instead\n",
      "  warnings.warn('DeprecationWarning: pretrains is deprecated, '\n",
      "2022-06-30 15:36:07,295 - mmtrack - INFO - initialize FasterRCNN with init_cfg {'type': 'Pretrained', 'checkpoint': 'https://download.openmmlab.com/mmtracking/mot/faster_rcnn/faster-rcnn_r50_fpn_4e_mot17-ffa52ae7.pth'}\n",
      "2022-06-30 15:36:07,296 - mmcv - INFO - load model from: https://download.openmmlab.com/mmtracking/mot/faster_rcnn/faster-rcnn_r50_fpn_4e_mot17-ffa52ae7.pth\n",
      "2022-06-30 15:36:07,296 - mmcv - INFO - load checkpoint from http path: https://download.openmmlab.com/mmtracking/mot/faster_rcnn/faster-rcnn_r50_fpn_4e_mot17-ffa52ae7.pth\n",
      "Downloading: \"https://download.openmmlab.com/mmtracking/mot/faster_rcnn/faster-rcnn_r50_fpn_4e_mot17-ffa52ae7.pth\" to /home/featurize/.cache/torch/hub/checkpoints/faster-rcnn_r50_fpn_4e_mot17-ffa52ae7.pth\n",
      "100%|█████████████████████████████████████████| 158M/158M [00:01<00:00, 104MB/s]\n",
      "2022-06-30 15:36:09,072 - mmtrack - INFO - initialize BaseReID with init_cfg {'type': 'Pretrained', 'checkpoint': 'https://download.openmmlab.com/mmtracking/mot/reid/reid_r50_6e_mot17-4bf6b63d.pth'}\n",
      "2022-06-30 15:36:09,072 - mmcv - INFO - load model from: https://download.openmmlab.com/mmtracking/mot/reid/reid_r50_6e_mot17-4bf6b63d.pth\n",
      "2022-06-30 15:36:09,072 - mmcv - INFO - load checkpoint from http path: https://download.openmmlab.com/mmtracking/mot/reid/reid_r50_6e_mot17-4bf6b63d.pth\n",
      "Downloading: \"https://download.openmmlab.com/mmtracking/mot/reid/reid_r50_6e_mot17-4bf6b63d.pth\" to /home/featurize/.cache/torch/hub/checkpoints/reid_r50_6e_mot17-4bf6b63d.pth\n",
      "100%|██████████████████████████████████████| 98.6M/98.6M [00:01<00:00, 98.0MB/s]\n",
      "Warning: The model doesn't have classes\n",
      "load checkpoint from http path: https://download.openmmlab.com/mmpose/top_down/resnet/res50_coco_256x192-ec54d7f3_20200709.pth\n",
      "Running inference...\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 99/99, 2.0 task/s, elapsed: 51s, ETA:     0s\n"
     ]
    }
   ],
   "source": [
    "!python demo/top_down_pose_tracking_demo_with_mmtracking.py \\\n",
    "        demo/mmtracking_cfg/tracktor_faster-rcnn_r50_fpn_4e_mot17-private.py \\\n",
    "        configs/body/2d_kpt_sview_rgb_img/topdown_heatmap/coco/res50_coco_256x192.py \\\n",
    "        https://download.openmmlab.com/mmpose/top_down/resnet/res50_coco_256x192-ec54d7f3_20200709.pth \\\n",
    "        --video-path data/mot_people_short.mp4 \\\n",
    "        --out-video-root outputs/D1/D1_3_mmtracking_single_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8da0d73-61bd-4c85-8f62-571ade81053c",
   "metadata": {},
   "source": [
    "### 多帧视频预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79d7d3b2-14a7-42c9-bc98-2ca1a91f423b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model...\n",
      "/home/featurize/work/MMPose教程/mmtracking/mmtrack/models/mot/tracktor.py:28: UserWarning: DeprecationWarning: pretrains is deprecated, please use \"init_cfg\" instead\n",
      "  warnings.warn('DeprecationWarning: pretrains is deprecated, '\n",
      "2022-06-30 15:38:20,795 - mmtrack - INFO - initialize FasterRCNN with init_cfg {'type': 'Pretrained', 'checkpoint': 'https://download.openmmlab.com/mmtracking/mot/faster_rcnn/faster-rcnn_r50_fpn_4e_mot17-ffa52ae7.pth'}\n",
      "2022-06-30 15:38:20,795 - mmcv - INFO - load model from: https://download.openmmlab.com/mmtracking/mot/faster_rcnn/faster-rcnn_r50_fpn_4e_mot17-ffa52ae7.pth\n",
      "2022-06-30 15:38:20,795 - mmcv - INFO - load checkpoint from http path: https://download.openmmlab.com/mmtracking/mot/faster_rcnn/faster-rcnn_r50_fpn_4e_mot17-ffa52ae7.pth\n",
      "2022-06-30 15:38:20,955 - mmtrack - INFO - initialize BaseReID with init_cfg {'type': 'Pretrained', 'checkpoint': 'https://download.openmmlab.com/mmtracking/mot/reid/reid_r50_6e_mot17-4bf6b63d.pth'}\n",
      "2022-06-30 15:38:20,956 - mmcv - INFO - load model from: https://download.openmmlab.com/mmtracking/mot/reid/reid_r50_6e_mot17-4bf6b63d.pth\n",
      "2022-06-30 15:38:20,956 - mmcv - INFO - load checkpoint from http path: https://download.openmmlab.com/mmtracking/mot/reid/reid_r50_6e_mot17-4bf6b63d.pth\n",
      "Warning: The model doesn't have classes\n",
      "load checkpoint from http path: https://download.openmmlab.com/mmpose/top_down/posewarper/hrnet_w48_posetrack18_384x288_posewarper_stage2-4abf88db_20211130.pth\n",
      "Running inference...\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 99/99, 0.6 task/s, elapsed: 174s, ETA:     0s\n"
     ]
    }
   ],
   "source": [
    "!python demo/top_down_pose_tracking_demo_with_mmtracking.py \\\n",
    "    demo/mmtracking_cfg/tracktor_faster-rcnn_r50_fpn_4e_mot17-private.py \\\n",
    "    configs/body/2d_kpt_sview_rgb_vid/posewarper/posetrack18/hrnet_w48_posetrack18_384x288_posewarper_stage2.py \\\n",
    "    https://download.openmmlab.com/mmpose/top_down/posewarper/hrnet_w48_posetrack18_384x288_posewarper_stage2-4abf88db_20211130.pth  \\\n",
    "    --video-path data/mot_people_short.mp4 \\\n",
    "    --out-video-root outputs/D1/D1_4_mmtracking_multi_frames \\\n",
    "    --use-multi-frames \\\n",
    "    --online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4c092a-c0d5-42e8-b5c1-ec8f697e18fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
