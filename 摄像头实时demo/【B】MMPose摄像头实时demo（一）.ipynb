{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f64a5d48",
   "metadata": {},
   "source": [
    "# MMPose摄像头实时demo\n",
    "\n",
    "同济子豪兄 2022-6-22"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab5ece2",
   "metadata": {},
   "source": [
    "参考文档：https://github.com/open-mmlab/mmpose/blob/master/demo/docs/webcam_demo.md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8e471f",
   "metadata": {},
   "source": [
    "## 进入 MMPose 主目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8fda0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('mmpose')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e94c80",
   "metadata": {},
   "source": [
    "## 测试摄像头"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "028683ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 运行后按 q 键退出 \n",
    "!python demo/webcam_demo.py --config demo/webcam_cfg/test_camera.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689d7035",
   "metadata": {},
   "source": [
    "## 修改 config 文件"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01974791",
   "metadata": {},
   "source": [
    "进入`mmpose/demo/webcam_cfg`目录，\n",
    "\n",
    "打开`pose_estimation.py`，在`type='DetectorNode'`、两个`type='TopDownPoseEstimatorNode'`的dict中添加`device='cpu',`\n",
    "\n",
    "打开`pose_tracking.py`，修改`type='PoseTrackerNode'`中为`device='cpu'`\n",
    "\n",
    "打开`gesture_recognition.py`，在`type='DetectorNode'`、`type='HandGestureRecognizerNode'`的dict中添加`device='cpu',`\n",
    "\n",
    "如果想预测现有的视频文件，将`camera_id`的值修改为视频路径即可。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb290494",
   "metadata": {},
   "source": [
    "## 墨镜、大眼睛特效"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2546df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from http path: https://download.openmmlab.com/mmdetection/v2.0/ssd/ssdlite_mobilenetv2_scratch_600e_coco/ssdlite_mobilenetv2_scratch_600e_coco_20210629_110627-974d9307.pth\n",
      "load checkpoint from http path: https://download.openmmlab.com/mmpose/top_down/vipnas/vipnas_mbv3_coco_wholebody_256x192_dark-e2158108_20211205.pth\n",
      "load checkpoint from http path: https://download.openmmlab.com/mmpose/animal/hrnet/hrnet_w32_animalpose_256x256-1aa7f075_20210426.pth\n",
      "/Users/tommy/opt/anaconda3/envs/open-mmlab/lib/python3.7/site-packages/mmdet/datasets/utils.py:69: UserWarning: \"ImageToTensor\" pipeline is replaced by \"DefaultFormatBundle\" for batch inference. It is recommended to manually replace it in the test data pipeline in your config file.\n",
      "  'data pipeline in your config file.', UserWarning)\n",
      "/Users/tommy/opt/anaconda3/envs/open-mmlab/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/tommy/opt/anaconda3/envs/open-mmlab/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "!python3 demo/webcam_demo.py --cpu\n",
    "\n",
    "# !python3 demo/webcam_demo.py --cuda\n",
    "\n",
    "# 或运行\n",
    "# !python3 demo/webcam_demo.py --config demo/webcam_cfg/pose_estimation.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503d7817",
   "metadata": {},
   "source": [
    "## 人体姿态追踪"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8642f459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from http path: https://download.openmmlab.com/mmdetection/v2.0/ssd/ssdlite_mobilenetv2_scratch_600e_coco/ssdlite_mobilenetv2_scratch_600e_coco_20210629_110627-974d9307.pth\n",
      "load checkpoint from http path: https://download.openmmlab.com/mmpose/top_down/vipnas/vipnas_mbv3_coco_wholebody_256x192_dark-e2158108_20211205.pth\n",
      "/Users/tommy/opt/anaconda3/envs/open-mmlab/lib/python3.7/site-packages/mmdet/datasets/utils.py:69: UserWarning: \"ImageToTensor\" pipeline is replaced by \"DefaultFormatBundle\" for batch inference. It is recommended to manually replace it in the test data pipeline in your config file.\n",
      "  'data pipeline in your config file.', UserWarning)\n",
      "/Users/tommy/opt/anaconda3/envs/open-mmlab/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/tommy/opt/anaconda3/envs/open-mmlab/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "!python3 demo/webcam_demo.py --config demo/webcam_cfg/pose_tracking.py --cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3072e7",
   "metadata": {},
   "source": [
    "## 手势识别"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213d698a",
   "metadata": {},
   "source": [
    "NVGesture数据集的 25 类手势\n",
    "\n",
    "论文：https://research.nvidia.com/sites/default/files/pubs/2016-06_Online-Detection-and/NVIDIA_R3DCNN_cvpr2016.pdf\n",
    "\n",
    "![手势识别类别](img/nvgesture.png)\n",
    "\n",
    "0: 'five fingers move right',\n",
    "\n",
    "1: 'five fingers move left',\n",
    "\n",
    "2: 'five fingers move up',\n",
    "\n",
    "3: 'five fingers move down',\n",
    "\n",
    "4: 'two fingers move right',\n",
    "\n",
    "5: 'two fingers move left',\n",
    "\n",
    "6: 'two fingers move up',\n",
    "\n",
    "7: 'two fingers move down',\n",
    "\n",
    "8: 'click',\n",
    "\n",
    "9: 'beckoned',\n",
    "\n",
    "10: 'stretch hand',\n",
    "\n",
    "11: 'shake hand',\n",
    "\n",
    "12: 'one',\n",
    "\n",
    "13: 'two',\n",
    "\n",
    "14: 'three',\n",
    "\n",
    "15: 'lift up',\n",
    "\n",
    "16: 'press down',\n",
    "\n",
    "17: 'push',\n",
    "\n",
    "18: 'shrink',\n",
    "\n",
    "19: 'levorotation',\n",
    "\n",
    "20: 'dextrorotation',\n",
    "\n",
    "21: 'two fingers prod',\n",
    "\n",
    "22: 'grab',\n",
    "\n",
    "23: 'thumbs up',\n",
    "\n",
    "24: 'OK'\n",
    "\n",
    "详细配置文件见`configs/_base_/datasets/nvgesture.py`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7bc4d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from http path: https://download.openmmlab.com/mmpose/mmdet_pretrained/ssdlite_mobilenetv2_scratch_600e_onehand-4f9f8686_20220523.pth\n",
      "load checkpoint from http path: https://download.openmmlab.com/mmpose/gesture/mtut/i3d_nvgesture_bbox_112x112_fps15-363b5956_20220530.pth\n",
      "The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: backbone.depth.conv3d_1a_7x7.conv3d.weight, backbone.depth.conv3d_1a_7x7.batch3d.weight, backbone.depth.conv3d_1a_7x7.batch3d.bias, backbone.depth.conv3d_1a_7x7.batch3d.running_mean, backbone.depth.conv3d_1a_7x7.batch3d.running_var, backbone.depth.conv3d_1a_7x7.batch3d.num_batches_tracked, backbone.depth.conv3d_2b_1x1.conv3d.weight, backbone.depth.conv3d_2b_1x1.batch3d.weight, backbone.depth.conv3d_2b_1x1.batch3d.bias, backbone.depth.conv3d_2b_1x1.batch3d.running_mean, backbone.depth.conv3d_2b_1x1.batch3d.running_var, backbone.depth.conv3d_2b_1x1.batch3d.num_batches_tracked, backbone.depth.conv3d_2c_3x3.conv3d.weight, backbone.depth.conv3d_2c_3x3.batch3d.weight, backbone.depth.conv3d_2c_3x3.batch3d.bias, backbone.depth.conv3d_2c_3x3.batch3d.running_mean, backbone.depth.conv3d_2c_3x3.batch3d.running_var, backbone.depth.conv3d_2c_3x3.batch3d.num_batches_tracked, backbone.depth.mixed_3b.branch_0.conv3d.weight, backbone.depth.mixed_3b.branch_0.batch3d.weight, backbone.depth.mixed_3b.branch_0.batch3d.bias, backbone.depth.mixed_3b.branch_0.batch3d.running_mean, backbone.depth.mixed_3b.branch_0.batch3d.running_var, backbone.depth.mixed_3b.branch_0.batch3d.num_batches_tracked, backbone.depth.mixed_3b.branch_1.0.conv3d.weight, backbone.depth.mixed_3b.branch_1.0.batch3d.weight, backbone.depth.mixed_3b.branch_1.0.batch3d.bias, backbone.depth.mixed_3b.branch_1.0.batch3d.running_mean, backbone.depth.mixed_3b.branch_1.0.batch3d.running_var, backbone.depth.mixed_3b.branch_1.0.batch3d.num_batches_tracked, backbone.depth.mixed_3b.branch_1.1.conv3d.weight, backbone.depth.mixed_3b.branch_1.1.batch3d.weight, backbone.depth.mixed_3b.branch_1.1.batch3d.bias, backbone.depth.mixed_3b.branch_1.1.batch3d.running_mean, backbone.depth.mixed_3b.branch_1.1.batch3d.running_var, backbone.depth.mixed_3b.branch_1.1.batch3d.num_batches_tracked, backbone.depth.mixed_3b.branch_2.0.conv3d.weight, backbone.depth.mixed_3b.branch_2.0.batch3d.weight, backbone.depth.mixed_3b.branch_2.0.batch3d.bias, backbone.depth.mixed_3b.branch_2.0.batch3d.running_mean, backbone.depth.mixed_3b.branch_2.0.batch3d.running_var, backbone.depth.mixed_3b.branch_2.0.batch3d.num_batches_tracked, backbone.depth.mixed_3b.branch_2.1.conv3d.weight, backbone.depth.mixed_3b.branch_2.1.batch3d.weight, backbone.depth.mixed_3b.branch_2.1.batch3d.bias, backbone.depth.mixed_3b.branch_2.1.batch3d.running_mean, backbone.depth.mixed_3b.branch_2.1.batch3d.running_var, backbone.depth.mixed_3b.branch_2.1.batch3d.num_batches_tracked, backbone.depth.mixed_3b.branch_3.1.conv3d.weight, backbone.depth.mixed_3b.branch_3.1.batch3d.weight, backbone.depth.mixed_3b.branch_3.1.batch3d.bias, backbone.depth.mixed_3b.branch_3.1.batch3d.running_mean, backbone.depth.mixed_3b.branch_3.1.batch3d.running_var, backbone.depth.mixed_3b.branch_3.1.batch3d.num_batches_tracked, backbone.depth.mixed_3c.branch_0.conv3d.weight, backbone.depth.mixed_3c.branch_0.batch3d.weight, backbone.depth.mixed_3c.branch_0.batch3d.bias, backbone.depth.mixed_3c.branch_0.batch3d.running_mean, backbone.depth.mixed_3c.branch_0.batch3d.running_var, backbone.depth.mixed_3c.branch_0.batch3d.num_batches_tracked, backbone.depth.mixed_3c.branch_1.0.conv3d.weight, backbone.depth.mixed_3c.branch_1.0.batch3d.weight, backbone.depth.mixed_3c.branch_1.0.batch3d.bias, backbone.depth.mixed_3c.branch_1.0.batch3d.running_mean, backbone.depth.mixed_3c.branch_1.0.batch3d.running_var, backbone.depth.mixed_3c.branch_1.0.batch3d.num_batches_tracked, backbone.depth.mixed_3c.branch_1.1.conv3d.weight, backbone.depth.mixed_3c.branch_1.1.batch3d.weight, backbone.depth.mixed_3c.branch_1.1.batch3d.bias, backbone.depth.mixed_3c.branch_1.1.batch3d.running_mean, backbone.depth.mixed_3c.branch_1.1.batch3d.running_var, backbone.depth.mixed_3c.branch_1.1.batch3d.num_batches_tracked, backbone.depth.mixed_3c.branch_2.0.conv3d.weight, backbone.depth.mixed_3c.branch_2.0.batch3d.weight, backbone.depth.mixed_3c.branch_2.0.batch3d.bias, backbone.depth.mixed_3c.branch_2.0.batch3d.running_mean, backbone.depth.mixed_3c.branch_2.0.batch3d.running_var, backbone.depth.mixed_3c.branch_2.0.batch3d.num_batches_tracked, backbone.depth.mixed_3c.branch_2.1.conv3d.weight, backbone.depth.mixed_3c.branch_2.1.batch3d.weight, backbone.depth.mixed_3c.branch_2.1.batch3d.bias, backbone.depth.mixed_3c.branch_2.1.batch3d.running_mean, backbone.depth.mixed_3c.branch_2.1.batch3d.running_var, backbone.depth.mixed_3c.branch_2.1.batch3d.num_batches_tracked, backbone.depth.mixed_3c.branch_3.1.conv3d.weight, backbone.depth.mixed_3c.branch_3.1.batch3d.weight, backbone.depth.mixed_3c.branch_3.1.batch3d.bias, backbone.depth.mixed_3c.branch_3.1.batch3d.running_mean, backbone.depth.mixed_3c.branch_3.1.batch3d.running_var, backbone.depth.mixed_3c.branch_3.1.batch3d.num_batches_tracked, backbone.depth.mixed_4b.branch_0.conv3d.weight, backbone.depth.mixed_4b.branch_0.batch3d.weight, backbone.depth.mixed_4b.branch_0.batch3d.bias, backbone.depth.mixed_4b.branch_0.batch3d.running_mean, backbone.depth.mixed_4b.branch_0.batch3d.running_var, backbone.depth.mixed_4b.branch_0.batch3d.num_batches_tracked, backbone.depth.mixed_4b.branch_1.0.conv3d.weight, backbone.depth.mixed_4b.branch_1.0.batch3d.weight, backbone.depth.mixed_4b.branch_1.0.batch3d.bias, backbone.depth.mixed_4b.branch_1.0.batch3d.running_mean, backbone.depth.mixed_4b.branch_1.0.batch3d.running_var, backbone.depth.mixed_4b.branch_1.0.batch3d.num_batches_tracked, backbone.depth.mixed_4b.branch_1.1.conv3d.weight, backbone.depth.mixed_4b.branch_1.1.batch3d.weight, backbone.depth.mixed_4b.branch_1.1.batch3d.bias, backbone.depth.mixed_4b.branch_1.1.batch3d.running_mean, backbone.depth.mixed_4b.branch_1.1.batch3d.running_var, backbone.depth.mixed_4b.branch_1.1.batch3d.num_batches_tracked, backbone.depth.mixed_4b.branch_2.0.conv3d.weight, backbone.depth.mixed_4b.branch_2.0.batch3d.weight, backbone.depth.mixed_4b.branch_2.0.batch3d.bias, backbone.depth.mixed_4b.branch_2.0.batch3d.running_mean, backbone.depth.mixed_4b.branch_2.0.batch3d.running_var, backbone.depth.mixed_4b.branch_2.0.batch3d.num_batches_tracked, backbone.depth.mixed_4b.branch_2.1.conv3d.weight, backbone.depth.mixed_4b.branch_2.1.batch3d.weight, backbone.depth.mixed_4b.branch_2.1.batch3d.bias, backbone.depth.mixed_4b.branch_2.1.batch3d.running_mean, backbone.depth.mixed_4b.branch_2.1.batch3d.running_var, backbone.depth.mixed_4b.branch_2.1.batch3d.num_batches_tracked, backbone.depth.mixed_4b.branch_3.1.conv3d.weight, backbone.depth.mixed_4b.branch_3.1.batch3d.weight, backbone.depth.mixed_4b.branch_3.1.batch3d.bias, backbone.depth.mixed_4b.branch_3.1.batch3d.running_mean, backbone.depth.mixed_4b.branch_3.1.batch3d.running_var, backbone.depth.mixed_4b.branch_3.1.batch3d.num_batches_tracked, backbone.depth.mixed_4c.branch_0.conv3d.weight, backbone.depth.mixed_4c.branch_0.batch3d.weight, backbone.depth.mixed_4c.branch_0.batch3d.bias, backbone.depth.mixed_4c.branch_0.batch3d.running_mean, backbone.depth.mixed_4c.branch_0.batch3d.running_var, backbone.depth.mixed_4c.branch_0.batch3d.num_batches_tracked, backbone.depth.mixed_4c.branch_1.0.conv3d.weight, backbone.depth.mixed_4c.branch_1.0.batch3d.weight, backbone.depth.mixed_4c.branch_1.0.batch3d.bias, backbone.depth.mixed_4c.branch_1.0.batch3d.running_mean, backbone.depth.mixed_4c.branch_1.0.batch3d.running_var, backbone.depth.mixed_4c.branch_1.0.batch3d.num_batches_tracked, backbone.depth.mixed_4c.branch_1.1.conv3d.weight, backbone.depth.mixed_4c.branch_1.1.batch3d.weight, backbone.depth.mixed_4c.branch_1.1.batch3d.bias, backbone.depth.mixed_4c.branch_1.1.batch3d.running_mean, backbone.depth.mixed_4c.branch_1.1.batch3d.running_var, backbone.depth.mixed_4c.branch_1.1.batch3d.num_batches_tracked, backbone.depth.mixed_4c.branch_2.0.conv3d.weight, backbone.depth.mixed_4c.branch_2.0.batch3d.weight, backbone.depth.mixed_4c.branch_2.0.batch3d.bias, backbone.depth.mixed_4c.branch_2.0.batch3d.running_mean, backbone.depth.mixed_4c.branch_2.0.batch3d.running_var, backbone.depth.mixed_4c.branch_2.0.batch3d.num_batches_tracked, backbone.depth.mixed_4c.branch_2.1.conv3d.weight, backbone.depth.mixed_4c.branch_2.1.batch3d.weight, backbone.depth.mixed_4c.branch_2.1.batch3d.bias, backbone.depth.mixed_4c.branch_2.1.batch3d.running_mean, backbone.depth.mixed_4c.branch_2.1.batch3d.running_var, backbone.depth.mixed_4c.branch_2.1.batch3d.num_batches_tracked, backbone.depth.mixed_4c.branch_3.1.conv3d.weight, backbone.depth.mixed_4c.branch_3.1.batch3d.weight, backbone.depth.mixed_4c.branch_3.1.batch3d.bias, backbone.depth.mixed_4c.branch_3.1.batch3d.running_mean, backbone.depth.mixed_4c.branch_3.1.batch3d.running_var, backbone.depth.mixed_4c.branch_3.1.batch3d.num_batches_tracked, backbone.depth.mixed_4d.branch_0.conv3d.weight, backbone.depth.mixed_4d.branch_0.batch3d.weight, backbone.depth.mixed_4d.branch_0.batch3d.bias, backbone.depth.mixed_4d.branch_0.batch3d.running_mean, backbone.depth.mixed_4d.branch_0.batch3d.running_var, backbone.depth.mixed_4d.branch_0.batch3d.num_batches_tracked, backbone.depth.mixed_4d.branch_1.0.conv3d.weight, backbone.depth.mixed_4d.branch_1.0.batch3d.weight, backbone.depth.mixed_4d.branch_1.0.batch3d.bias, backbone.depth.mixed_4d.branch_1.0.batch3d.running_mean, backbone.depth.mixed_4d.branch_1.0.batch3d.running_var, backbone.depth.mixed_4d.branch_1.0.batch3d.num_batches_tracked, backbone.depth.mixed_4d.branch_1.1.conv3d.weight, backbone.depth.mixed_4d.branch_1.1.batch3d.weight, backbone.depth.mixed_4d.branch_1.1.batch3d.bias, backbone.depth.mixed_4d.branch_1.1.batch3d.running_mean, backbone.depth.mixed_4d.branch_1.1.batch3d.running_var, backbone.depth.mixed_4d.branch_1.1.batch3d.num_batches_tracked, backbone.depth.mixed_4d.branch_2.0.conv3d.weight, backbone.depth.mixed_4d.branch_2.0.batch3d.weight, backbone.depth.mixed_4d.branch_2.0.batch3d.bias, backbone.depth.mixed_4d.branch_2.0.batch3d.running_mean, backbone.depth.mixed_4d.branch_2.0.batch3d.running_var, backbone.depth.mixed_4d.branch_2.0.batch3d.num_batches_tracked, backbone.depth.mixed_4d.branch_2.1.conv3d.weight, backbone.depth.mixed_4d.branch_2.1.batch3d.weight, backbone.depth.mixed_4d.branch_2.1.batch3d.bias, backbone.depth.mixed_4d.branch_2.1.batch3d.running_mean, backbone.depth.mixed_4d.branch_2.1.batch3d.running_var, backbone.depth.mixed_4d.branch_2.1.batch3d.num_batches_tracked, backbone.depth.mixed_4d.branch_3.1.conv3d.weight, backbone.depth.mixed_4d.branch_3.1.batch3d.weight, backbone.depth.mixed_4d.branch_3.1.batch3d.bias, backbone.depth.mixed_4d.branch_3.1.batch3d.running_mean, backbone.depth.mixed_4d.branch_3.1.batch3d.running_var, backbone.depth.mixed_4d.branch_3.1.batch3d.num_batches_tracked, backbone.depth.mixed_4e.branch_0.conv3d.weight, backbone.depth.mixed_4e.branch_0.batch3d.weight, backbone.depth.mixed_4e.branch_0.batch3d.bias, backbone.depth.mixed_4e.branch_0.batch3d.running_mean, backbone.depth.mixed_4e.branch_0.batch3d.running_var, backbone.depth.mixed_4e.branch_0.batch3d.num_batches_tracked, backbone.depth.mixed_4e.branch_1.0.conv3d.weight, backbone.depth.mixed_4e.branch_1.0.batch3d.weight, backbone.depth.mixed_4e.branch_1.0.batch3d.bias, backbone.depth.mixed_4e.branch_1.0.batch3d.running_mean, backbone.depth.mixed_4e.branch_1.0.batch3d.running_var, backbone.depth.mixed_4e.branch_1.0.batch3d.num_batches_tracked, backbone.depth.mixed_4e.branch_1.1.conv3d.weight, backbone.depth.mixed_4e.branch_1.1.batch3d.weight, backbone.depth.mixed_4e.branch_1.1.batch3d.bias, backbone.depth.mixed_4e.branch_1.1.batch3d.running_mean, backbone.depth.mixed_4e.branch_1.1.batch3d.running_var, backbone.depth.mixed_4e.branch_1.1.batch3d.num_batches_tracked, backbone.depth.mixed_4e.branch_2.0.conv3d.weight, backbone.depth.mixed_4e.branch_2.0.batch3d.weight, backbone.depth.mixed_4e.branch_2.0.batch3d.bias, backbone.depth.mixed_4e.branch_2.0.batch3d.running_mean, backbone.depth.mixed_4e.branch_2.0.batch3d.running_var, backbone.depth.mixed_4e.branch_2.0.batch3d.num_batches_tracked, backbone.depth.mixed_4e.branch_2.1.conv3d.weight, backbone.depth.mixed_4e.branch_2.1.batch3d.weight, backbone.depth.mixed_4e.branch_2.1.batch3d.bias, backbone.depth.mixed_4e.branch_2.1.batch3d.running_mean, backbone.depth.mixed_4e.branch_2.1.batch3d.running_var, backbone.depth.mixed_4e.branch_2.1.batch3d.num_batches_tracked, backbone.depth.mixed_4e.branch_3.1.conv3d.weight, backbone.depth.mixed_4e.branch_3.1.batch3d.weight, backbone.depth.mixed_4e.branch_3.1.batch3d.bias, backbone.depth.mixed_4e.branch_3.1.batch3d.running_mean, backbone.depth.mixed_4e.branch_3.1.batch3d.running_var, backbone.depth.mixed_4e.branch_3.1.batch3d.num_batches_tracked, backbone.depth.mixed_4f.branch_0.conv3d.weight, backbone.depth.mixed_4f.branch_0.batch3d.weight, backbone.depth.mixed_4f.branch_0.batch3d.bias, backbone.depth.mixed_4f.branch_0.batch3d.running_mean, backbone.depth.mixed_4f.branch_0.batch3d.running_var, backbone.depth.mixed_4f.branch_0.batch3d.num_batches_tracked, backbone.depth.mixed_4f.branch_1.0.conv3d.weight, backbone.depth.mixed_4f.branch_1.0.batch3d.weight, backbone.depth.mixed_4f.branch_1.0.batch3d.bias, backbone.depth.mixed_4f.branch_1.0.batch3d.running_mean, backbone.depth.mixed_4f.branch_1.0.batch3d.running_var, backbone.depth.mixed_4f.branch_1.0.batch3d.num_batches_tracked, backbone.depth.mixed_4f.branch_1.1.conv3d.weight, backbone.depth.mixed_4f.branch_1.1.batch3d.weight, backbone.depth.mixed_4f.branch_1.1.batch3d.bias, backbone.depth.mixed_4f.branch_1.1.batch3d.running_mean, backbone.depth.mixed_4f.branch_1.1.batch3d.running_var, backbone.depth.mixed_4f.branch_1.1.batch3d.num_batches_tracked, backbone.depth.mixed_4f.branch_2.0.conv3d.weight, backbone.depth.mixed_4f.branch_2.0.batch3d.weight, backbone.depth.mixed_4f.branch_2.0.batch3d.bias, backbone.depth.mixed_4f.branch_2.0.batch3d.running_mean, backbone.depth.mixed_4f.branch_2.0.batch3d.running_var, backbone.depth.mixed_4f.branch_2.0.batch3d.num_batches_tracked, backbone.depth.mixed_4f.branch_2.1.conv3d.weight, backbone.depth.mixed_4f.branch_2.1.batch3d.weight, backbone.depth.mixed_4f.branch_2.1.batch3d.bias, backbone.depth.mixed_4f.branch_2.1.batch3d.running_mean, backbone.depth.mixed_4f.branch_2.1.batch3d.running_var, backbone.depth.mixed_4f.branch_2.1.batch3d.num_batches_tracked, backbone.depth.mixed_4f.branch_3.1.conv3d.weight, backbone.depth.mixed_4f.branch_3.1.batch3d.weight, backbone.depth.mixed_4f.branch_3.1.batch3d.bias, backbone.depth.mixed_4f.branch_3.1.batch3d.running_mean, backbone.depth.mixed_4f.branch_3.1.batch3d.running_var, backbone.depth.mixed_4f.branch_3.1.batch3d.num_batches_tracked, backbone.depth.mixed_5b.branch_0.conv3d.weight, backbone.depth.mixed_5b.branch_0.batch3d.weight, backbone.depth.mixed_5b.branch_0.batch3d.bias, backbone.depth.mixed_5b.branch_0.batch3d.running_mean, backbone.depth.mixed_5b.branch_0.batch3d.running_var, backbone.depth.mixed_5b.branch_0.batch3d.num_batches_tracked, backbone.depth.mixed_5b.branch_1.0.conv3d.weight, backbone.depth.mixed_5b.branch_1.0.batch3d.weight, backbone.depth.mixed_5b.branch_1.0.batch3d.bias, backbone.depth.mixed_5b.branch_1.0.batch3d.running_mean, backbone.depth.mixed_5b.branch_1.0.batch3d.running_var, backbone.depth.mixed_5b.branch_1.0.batch3d.num_batches_tracked, backbone.depth.mixed_5b.branch_1.1.conv3d.weight, backbone.depth.mixed_5b.branch_1.1.batch3d.weight, backbone.depth.mixed_5b.branch_1.1.batch3d.bias, backbone.depth.mixed_5b.branch_1.1.batch3d.running_mean, backbone.depth.mixed_5b.branch_1.1.batch3d.running_var, backbone.depth.mixed_5b.branch_1.1.batch3d.num_batches_tracked, backbone.depth.mixed_5b.branch_2.0.conv3d.weight, backbone.depth.mixed_5b.branch_2.0.batch3d.weight, backbone.depth.mixed_5b.branch_2.0.batch3d.bias, backbone.depth.mixed_5b.branch_2.0.batch3d.running_mean, backbone.depth.mixed_5b.branch_2.0.batch3d.running_var, backbone.depth.mixed_5b.branch_2.0.batch3d.num_batches_tracked, backbone.depth.mixed_5b.branch_2.1.conv3d.weight, backbone.depth.mixed_5b.branch_2.1.batch3d.weight, backbone.depth.mixed_5b.branch_2.1.batch3d.bias, backbone.depth.mixed_5b.branch_2.1.batch3d.running_mean, backbone.depth.mixed_5b.branch_2.1.batch3d.running_var, backbone.depth.mixed_5b.branch_2.1.batch3d.num_batches_tracked, backbone.depth.mixed_5b.branch_3.1.conv3d.weight, backbone.depth.mixed_5b.branch_3.1.batch3d.weight, backbone.depth.mixed_5b.branch_3.1.batch3d.bias, backbone.depth.mixed_5b.branch_3.1.batch3d.running_mean, backbone.depth.mixed_5b.branch_3.1.batch3d.running_var, backbone.depth.mixed_5b.branch_3.1.batch3d.num_batches_tracked, backbone.depth.mixed_5c.branch_0.conv3d.weight, backbone.depth.mixed_5c.branch_0.batch3d.weight, backbone.depth.mixed_5c.branch_0.batch3d.bias, backbone.depth.mixed_5c.branch_0.batch3d.running_mean, backbone.depth.mixed_5c.branch_0.batch3d.running_var, backbone.depth.mixed_5c.branch_0.batch3d.num_batches_tracked, backbone.depth.mixed_5c.branch_1.0.conv3d.weight, backbone.depth.mixed_5c.branch_1.0.batch3d.weight, backbone.depth.mixed_5c.branch_1.0.batch3d.bias, backbone.depth.mixed_5c.branch_1.0.batch3d.running_mean, backbone.depth.mixed_5c.branch_1.0.batch3d.running_var, backbone.depth.mixed_5c.branch_1.0.batch3d.num_batches_tracked, backbone.depth.mixed_5c.branch_1.1.conv3d.weight, backbone.depth.mixed_5c.branch_1.1.batch3d.weight, backbone.depth.mixed_5c.branch_1.1.batch3d.bias, backbone.depth.mixed_5c.branch_1.1.batch3d.running_mean, backbone.depth.mixed_5c.branch_1.1.batch3d.running_var, backbone.depth.mixed_5c.branch_1.1.batch3d.num_batches_tracked, backbone.depth.mixed_5c.branch_2.0.conv3d.weight, backbone.depth.mixed_5c.branch_2.0.batch3d.weight, backbone.depth.mixed_5c.branch_2.0.batch3d.bias, backbone.depth.mixed_5c.branch_2.0.batch3d.running_mean, backbone.depth.mixed_5c.branch_2.0.batch3d.running_var, backbone.depth.mixed_5c.branch_2.0.batch3d.num_batches_tracked, backbone.depth.mixed_5c.branch_2.1.conv3d.weight, backbone.depth.mixed_5c.branch_2.1.batch3d.weight, backbone.depth.mixed_5c.branch_2.1.batch3d.bias, backbone.depth.mixed_5c.branch_2.1.batch3d.running_mean, backbone.depth.mixed_5c.branch_2.1.batch3d.running_var, backbone.depth.mixed_5c.branch_2.1.batch3d.num_batches_tracked, backbone.depth.mixed_5c.branch_3.1.conv3d.weight, backbone.depth.mixed_5c.branch_3.1.batch3d.weight, backbone.depth.mixed_5c.branch_3.1.batch3d.bias, backbone.depth.mixed_5c.branch_3.1.batch3d.running_mean, backbone.depth.mixed_5c.branch_3.1.batch3d.running_var, backbone.depth.mixed_5c.branch_3.1.batch3d.num_batches_tracked, cls_head.output_conv.depth.weight, cls_head.output_conv.depth.bias\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/tommy/opt/anaconda3/envs/open-mmlab/lib/python3.7/site-packages/mmdet/datasets/utils.py:69: UserWarning: \"ImageToTensor\" pipeline is replaced by \"DefaultFormatBundle\" for batch inference. It is recommended to manually replace it in the test data pipeline in your config file.\n",
      "  'data pipeline in your config file.', UserWarning)\n",
      "/Users/tommy/opt/anaconda3/envs/open-mmlab/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/tommy/opt/anaconda3/envs/open-mmlab/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "!python3 demo/webcam_demo.py --config demo/webcam_cfg/gesture_recognition.py --cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ee5de9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
